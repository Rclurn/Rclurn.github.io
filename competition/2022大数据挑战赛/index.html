<!DOCTYPE html>
<html><head>
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

   
    <meta name="author" content="摸铁校尉🥉">
  

   
    
    
    
    
    
    
    <meta name="keywords" content="Machine Learning,kagome">
  

   
    <meta name="description" content="记录生活点点点点点点点滴">
  

  <meta name="generator" content="Hugo 0.105.0">
  
  
  
  
  
  
  <title>2022大数据挑战赛 🌟 Rclurn</title>

  <meta property="og:title" content="2022大数据挑战赛" />
<meta property="og:description" content="记录生活点点点点点点点滴" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://Rclurn.github.io/competition/2022%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8C%91%E6%88%98%E8%B5%9B/" /><meta property="article:section" content="competition" />
<meta property="article:published_time" content="2023-12-30T00:30:10+08:00" />
<meta property="article:modified_time" content="2023-12-30T00:30:10+08:00" />


  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="2022大数据挑战赛"/>
<meta name="twitter:description" content="记录生活点点点点点点点滴"/>


  
  
  
  
  <link rel="stylesheet" href="https://Rclurn.github.io/assets/css/style.min.699f46622e3574a7f9ecca4c5877067845fe89ffcd9c4335df2dff23ddae215e.css" integrity="sha256-aZ9GYi41dKf57MpMWHcGeEX&#43;if/NnEM13y3/I92uIV4=">

  <script src="https://Rclurn.github.io/assets/js/main.min.182da266209851bc7c828aa7377f98f914e1e76c8decdd53a6cbe9bffea92cde.js" integrity="sha256-GC2iZiCYUbx8goqnN3&#43;Y&#43;RTh52yN7N1Tpsvpv/6pLN4="></script>
  
  </head><body><header class="header-container layout-block layout-padding">
  <div class="header-inner content-padding-large soft-size--large soft-style--box">
    <div class="header-logo">
      <a href="https://Rclurn.github.io/"><h1>Rclurn</h1></a>
    </div>
    <nav class="header-nav">
      <div class="header-nav--btn">
        <div class="btn-item"></div>
        <div class="btn-item"></div>
        <div class="btn-item"></div>
      </div>
      <div class="header-nav--list">
        <div>
          
          <a class="list-item soft-size--small soft-style--hover soft-style--active" href="/" title="">🏠Home</a>
          
          <a class="list-item soft-size--small soft-style--hover soft-style--active" href="/projects" title="">🤖Projects</a>
          
          <a class="list-item soft-size--small soft-style--hover soft-style--active" href="/paper" title="">📝Paper with code</a>
          
          <a class="list-item soft-size--small soft-style--hover soft-style--active" href="/algorithm" title="">👹Algorithm</a>
          
          <a class="list-item soft-size--small soft-style--hover soft-style--active" href="/about" title="">🤡About</a>
          
        </div>
      </div>
    </nav>
  </div>
</header><main id="content">
    

    <div class="single-container layout-block">
      <div class="article-info">
        <div class="article-header layout-padding">
          <div class="article-cover card-container content-padding-large soft-size--large soft-style--box img">

  <div class="card-cover">
    
      <img src="https://s2.loli.net/2023/12/30/5tWkBeZIU73mGns.jpg" alt="https://s2.loli.net/2023/12/30/5tWkBeZIU73mGns.jpg" />
    
  </div>

  <div class="card-text">
    <h1 class="card-text--title">2022大数据挑战赛</h1>
    
      <p class="card-text--row">2023-12-30 00:30</p>
      
      
      
        <ul class="card-text--tag">
          
            <li><a href="https://Rclurn.github.io/categories/%E7%AB%9E%E8%B5%9B/">竞赛</a></li></ul>
      

      
      
    
  </div>

</div>
        </div>

        <div class="article-content">
          <div class="markdown-body content-padding-large soft-size--large soft-style--box">
            <h2 id="任务解读">任务解读</h2>
<p>基于微信短视频号的短视频数据，利用短视频中常有的三种模态信息（文本、视频、音频）以及对应的分类标签信息，采用合理的机器学习算法对短视频进行分类预测。数据格式如下图所示：</p>
<p>
  <p><img src="https://s2.loli.net/2024/01/06/9JSyAEXxp3jvhQP.png" alt="" loading="lazy" /></p>
</p>
<p>其中，初赛提供了百万的无标注数据和十万的有标注数据用于训练，复赛阶段数据与初赛一致，主要区别在于初赛阶段提供由<a href="">Swin-Transformer</a>抽取的视频抽帧特征，而复赛阶段提供视频抽帧的原始图像。</p>
<h2 id="数据分析">数据分析</h2>
<p>1、数据类别分布不均衡</p>
<p>2、ASR/OCR存在识别不准确，Title文本数据图文不匹配的问题，这些都是训练时的噪声，直接进行图文的对比学习可能噪声很大，效果不好</p>
<p>3、ASR/OCR的识别错误相较于Title可能噪声更大，如何区别处理这些文本</p>
<p>4、如何利用无标签数据</p>
<h2 id="赛题思路">赛题思路</h2>
<p>整体思路：通过不同的模型抽取文本和视频的embedding表征，然后进行不同的组合（单流、双流）进行分类任务，并利用常见<a href="">Tricks</a>进行单个模型的调优，最后进行模型融合。</p>
<h3 id="单流模型">单流模型</h3>
<p>文本通过<a href="">Roberta-wwm-ext</a>抽取embedding表征，视频通过<a href="">Vit(Clip-Vit-B/16)</a>抽取embedding表征，然后将其在时间序列维度上进行拼接，作为最终的embedding表征送入12层的<a href="">Roberta-wwm-ext</a>的encoder模块中，最后取时间序列维度的均值作为[CLS]进行分类任务。为了使文本的embedding表征与视频的embedding表征尽量对齐，我们使用了<a href="">ITM</a>、<a href="">MFM</a>、和<a href="">MLM</a>三个预训练任务。</p>
<h3 id="双流模型">双流模型</h3>
<p>文本通过<a href="">Roberta-wwm-ext</a>抽取embedding表征，视频通过[<a href="">ClIP-B/16</a>抽取embedding表征，然后将图片表征作为Q，文本表征作为K、V送入3层的Attention模块中，进行文本与视频的Cross Attention，最后取时间序列维度的均值作为[CLS]进行分类任务。在预训练任务上，我们使用了<a href="">ITM</a>、<a href="">ITC</a>和<a href="">MLM</a>，值得一提的是这里的[ITC]和[ITM]与单流模型的有所不同，在实现双流模型的[ITC]和[ITM]时，我们借鉴了<a href="">ALBEF</a>这篇论文中的动量蒸馏思想并利用在<a href="">ITC</a>任务中获取的模型认为的难样本来进行<a href="">ITM</a>任务，加大了<a href="">ITM</a>任务的难度，同时也缓解了模型对于难样本边界模糊不清的情况。</p>
<h3 id="预训练任务">预训练任务</h3>
<h4 id="itcimage-text-contrastive-learning">ITC(Image-Text Contrastive Learning)</h4>
<p><a href="">ALBEF</a>借鉴了<a href="">MoCo</a>的动量蒸馏方法，维护了两个队列来存储单模态编码器的最新M个图像文本表示并将其作为当前batch图文对的负样本，为了保证队列中编码的一致性( 防止模型寻找到捷径：同一时刻的编码器编码的图文更相似)，队列中所存储的图文表征均采用动量模型生成。动量模型主要有两个作用：1、作为教师模型生成伪目标来指导原始模型进行训练；2、类似于MoCo，利用队列中的大量负样本实现对比学习。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>    self<span style="color:#f92672">.</span>_momentum_update() <span style="color:#75715e"># 依据编码器模型更新动量模型的参数</span>
</span></span><span style="display:flex;"><span>    image_embeds_m <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>visual_encoder_m(image) <span style="color:#75715e"># 获得图片的动量embedding表征</span>
</span></span><span style="display:flex;"><span>    image_feat_m <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>normalize(self<span style="color:#f92672">.</span>vision_proj_m(image_embeds_m[:,<span style="color:#ae81ff">0</span>,:]),dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)  
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 将当前batch的图片表征与队列中的其他所有图片表征进行拼接 [hidden_dim: batch_size + queue_size]</span>
</span></span><span style="display:flex;"><span>    image_feat_all <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([image_feat_m<span style="color:#f92672">.</span>t(),self<span style="color:#f92672">.</span>image_queue<span style="color:#f92672">.</span>clone()<span style="color:#f92672">.</span>detach()],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)                   
</span></span><span style="display:flex;"><span>    text_output_m <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>text_encoder_m<span style="color:#f92672">.</span>bert(text<span style="color:#f92672">.</span>input_ids, attention_mask <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>attention_mask,    
</span></span><span style="display:flex;"><span>                                             return_dict <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>, mode <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;text&#39;</span>)    
</span></span><span style="display:flex;"><span>    text_feat_m <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>normalize(self<span style="color:#f92672">.</span>text_proj_m(text_output_m<span style="color:#f92672">.</span>last_hidden_state[:,<span style="color:#ae81ff">0</span>,:]),dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>) 
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 将当前batch的文本表征与队列中的其他所有文本表征进行拼接 [hidden_dim: batch_size + queue_size]</span>
</span></span><span style="display:flex;"><span>    text_feat_all <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([text_feat_m<span style="color:#f92672">.</span>t(),self<span style="color:#f92672">.</span>text_queue<span style="color:#f92672">.</span>clone()<span style="color:#f92672">.</span>detach()],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 维度 [batch: batch_size + queue_size]</span>
</span></span><span style="display:flex;"><span>    sim_i2t_m <span style="color:#f92672">=</span> image_feat_m <span style="color:#f92672">@</span> text_feat_all <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>temp <span style="color:#75715e"># 计算当前batch的图片动量表征与队列所有文本动量表征的相似度</span>
</span></span><span style="display:flex;"><span>    sim_t2i_m <span style="color:#f92672">=</span> text_feat_m <span style="color:#f92672">@</span> image_feat_all <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>temp <span style="color:#75715e"># 计算当前batch的文本动量表征与队列所有图片动量表征的相似度</span>
</span></span><span style="display:flex;"><span>    sim_targets <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>zeros(sim_i2t_m<span style="color:#f92672">.</span>size())<span style="color:#f92672">.</span>to(image<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>    sim_targets<span style="color:#f92672">.</span>fill_diagonal_(<span style="color:#ae81ff">1</span>) <span style="color:#75715e"># 构造标签，主对角线为1，其余为0         </span>
</span></span><span style="display:flex;"><span>    sim_i2t_targets <span style="color:#f92672">=</span> alpha <span style="color:#f92672">*</span> F<span style="color:#f92672">.</span>softmax(sim_i2t_m, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> alpha) <span style="color:#f92672">*</span> sim_targets
</span></span><span style="display:flex;"><span>    sim_t2i_targets <span style="color:#f92672">=</span> alpha <span style="color:#f92672">*</span> F<span style="color:#f92672">.</span>softmax(sim_t2i_m, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>) <span style="color:#f92672">+</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> alpha) <span style="color:#f92672">*</span> sim_targets        
</span></span><span style="display:flex;"><span>sim_i2t <span style="color:#f92672">=</span> image_feat <span style="color:#f92672">@</span> text_feat_all <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>temp 
</span></span><span style="display:flex;"><span>sim_t2i <span style="color:#f92672">=</span> text_feat <span style="color:#f92672">@</span> image_feat_all <span style="color:#f92672">/</span> self<span style="color:#f92672">.</span>temp 
</span></span><span style="display:flex;"><span>loss_i2t <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>torch<span style="color:#f92672">.</span>sum(F<span style="color:#f92672">.</span>log_softmax(sim_i2t, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>sim_i2t_targets,dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>loss_t2i <span style="color:#f92672">=</span> <span style="color:#f92672">-</span>torch<span style="color:#f92672">.</span>sum(F<span style="color:#f92672">.</span>log_softmax(sim_t2i, dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">*</span>sim_t2i_targets,dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>mean() 
</span></span><span style="display:flex;"><span>loss_ita <span style="color:#f92672">=</span> (loss_i2t<span style="color:#f92672">+</span>loss_t2i)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>self<span style="color:#f92672">.</span>_dequeue_and_enqueue(image_feat_m, text_feat_m)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-tex" data-lang="tex"><span style="display:flex;"><span>1、为什么要视频作为Q、文本作为K、V进行Cross Attention？
</span></span><span style="display:flex;"><span>我们人为文本Title表达的意思可能更趋近于视频发布者想要表达的思想，而视频只是一个辅助作用，所以这样使用。当然，在实验的过程中，我们也尝试了反过来进行输入，但是效果并没有前者好。
</span></span></code></pre></div><h4 id="itmimage-text-match">ITM(Image-Text Match)</h4>
<p><a href="">ITM</a>任务主要用来判断一张图片和一段文本是否匹配，在<a href="">ALBEF</a>中，为了增大<a href="">ITM</a>任务的任务难度，选择图文较相似的负样本来进行图文匹配任务，具体负样本的选择依赖于<a href="">ITC</a>任务，在ITC任务中，我们得到了一个当前batch的图文相似度矩阵，选择所有负样本中与正样本相似度最高的那个样本来作为<a href="">ITM</a>任务的负样本进行二分类任务。</p>
<p>通过bert的的后6层获取图文的正样本表征</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>output_pos <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>text_encoder<span style="color:#f92672">.</span>bert(encoder_embeds <span style="color:#f92672">=</span> text_embeds, attention_mask <span style="color:#f92672">=</span> text<span style="color:#f92672">.</span>attention_mask,
</span></span><span style="display:flex;"><span>                                    encoder_hidden_states <span style="color:#f92672">=</span> image_embeds, 
</span></span><span style="display:flex;"><span>                                    encoder_attention_mask <span style="color:#f92672">=</span> image_atts,      
</span></span><span style="display:flex;"><span>                                    return_dict <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>, mode <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fusion&#39;</span>)    
</span></span></code></pre></div><p>通过<a href="">ITC</a>任务的相似度矩阵选择负样本，将相似度矩阵的对角线值填充为0(正样本，概率最高)，然后通过torch.multinomial()函数获得相似度矩阵中值最大的一个样本对应的索引。</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">with</span> torch<span style="color:#f92672">.</span>no_grad():
</span></span><span style="display:flex;"><span>    bs <span style="color:#f92672">=</span> image<span style="color:#f92672">.</span>size(<span style="color:#ae81ff">0</span>)          
</span></span><span style="display:flex;"><span>    weights_i2t <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(sim_i2t[:,:bs],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    weights_t2i <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(sim_t2i[:,:bs],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    weights_i2t<span style="color:#f92672">.</span>fill_diagonal_(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>    weights_t2i<span style="color:#f92672">.</span>fill_diagonal_(<span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># select a negative image for each text</span>
</span></span><span style="display:flex;"><span>image_embeds_neg <span style="color:#f92672">=</span> []    
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> b <span style="color:#f92672">in</span> range(bs):
</span></span><span style="display:flex;"><span>    neg_idx <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>multinomial(weights_t2i[b], <span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>    image_embeds_neg<span style="color:#f92672">.</span>append(image_embeds[neg_idx])
</span></span><span style="display:flex;"><span>    image_embeds_neg <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack(image_embeds_neg,dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)   
</span></span><span style="display:flex;"><span><span style="color:#75715e"># select a negative text for each image</span>
</span></span><span style="display:flex;"><span>text_embeds_neg <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>text_atts_neg <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> b <span style="color:#f92672">in</span> range(bs):
</span></span><span style="display:flex;"><span>    neg_idx <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>multinomial(weights_i2t[b], <span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>    text_embeds_neg<span style="color:#f92672">.</span>append(text_embeds[neg_idx])
</span></span><span style="display:flex;"><span>    text_atts_neg<span style="color:#f92672">.</span>append(text<span style="color:#f92672">.</span>attention_mask[neg_idx])
</span></span><span style="display:flex;"><span>    text_embeds_neg <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack(text_embeds_neg,dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)   
</span></span><span style="display:flex;"><span>    text_atts_neg <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>stack(text_atts_neg,dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span></code></pre></div><p>然后按照<code>pos_text</code>在前<code>neg_text</code>在后的形式拼接text，按照<code>neg_img</code>在前<code>pos_img</code>在后的方式拼接image，这样在进行cross attention后，输出的所有表征都将是负样本表征</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>text_embeds_all <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([text_embeds, text_embeds_neg],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)     
</span></span><span style="display:flex;"><span>text_atts_all <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([text<span style="color:#f92672">.</span>attention_mask, text_atts_neg],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)     
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>image_embeds_all <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([image_embeds_neg,image_embeds],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>image_atts_all <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([image_atts,image_atts],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>output_neg <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>text_encoder<span style="color:#f92672">.</span>bert(encoder_embeds <span style="color:#f92672">=</span> text_embeds_all, attention_mask <span style="color:#f92672">=</span> text_atts_all,
</span></span><span style="display:flex;"><span>                                    encoder_hidden_states <span style="color:#f92672">=</span> image_embeds_all,
</span></span><span style="display:flex;"><span>                                    encoder_attention_mask <span style="color:#f92672">=</span> image_atts_all,      
</span></span><span style="display:flex;"><span>                                    return_dict <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>, mode <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;fusion&#39;</span>)
</span></span></code></pre></div><p>最后将所有输出进行拼接并构造标签进行二分类任务</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span>vl_embeddings <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([output_pos<span style="color:#f92672">.</span>last_hidden_state[:,<span style="color:#ae81ff">0</span>,:], output_neg<span style="color:#f92672">.</span>last_hidden_state[:,<span style="color:#ae81ff">0</span>,:]],dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>vl_output <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>itm_head(vl_embeddings)            
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>itm_labels <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([torch<span style="color:#f92672">.</span>ones(bs,dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long),torch<span style="color:#f92672">.</span>zeros(<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>bs,dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long)],
</span></span><span style="display:flex;"><span>                       dim<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>to(image<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>loss_itm <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>cross_entropy(vl_output, itm_labels)  
</span></span></code></pre></div>
          </div>
        </div>
                 
      
  
  

  

  <div class="article-paging">
    
    
  </div>
</div>
  <aside class="widget-info">
    
<section class="aside-widget widget-author content-padding-large soft-size--large soft-style--box">
  <div class="widget-body">
    <div class="author-box avatar">
      
      <img class="author-avatar soft-size--round soft-style--box" src="https://s.gravatar.com/avatar/7b5a0b07a98895278cfa862b1f32ae8f?s=200&amp;r=g&amp;d=retro" alt="摸铁校尉🥉">
      
      <h2 class="author-name text-ellipsis">摸铁校尉🥉</h2>
      
      <p class="author-desc text-ellipsis">闭上眼睛，开始穿越!</p>
      
    </div>
  </div>
</section>


    

<section class="aside-widget widget-toc content-padding-large soft-size--large soft-style--box">
  <h2 class="widget-header">
    <div class="title">
      <span>Toc</span>
    </div>
  </h2>
  <div class="widget-body">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#任务解读">任务解读</a></li>
    <li><a href="#数据分析">数据分析</a></li>
    <li><a href="#赛题思路">赛题思路</a>
      <ul>
        <li><a href="#单流模型">单流模型</a></li>
        <li><a href="#双流模型">双流模型</a></li>
        <li><a href="#预训练任务">预训练任务</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</section>


    










<section class="aside-widget widget-articles content-padding-large soft-size--large soft-style--box">
  <h2 class="widget-header">
    <div class="title">
      <span>Related Posts</span>
    </div>
  </h2>
  <div class="widget-body">
    <ul class="post-list">
      
      
        <li class="post-item"><a href="/algorithm/deepseek-v2/">DeepSeek V2</a></li>
      
        <li class="post-item"><a href="/algorithm/baichuan-2/">Baichuan 2</a></li>
      
        <li class="post-item"><a href="/algorithm/speculative-decoding/">Speculative Decoding</a></li>
      
        <li class="post-item"><a href="/algorithm/transformer/">Transformer</a></li>
      
        <li class="post-item"><a href="/algorithm/baai-general-embeddings/">BAAI General Embeddings</a></li>
      
        <li class="post-item"><a href="/algorithm/direct-preference-optimization/">Direct Preference Optimization</a></li>
      
    </ul>
  </div>
</section>


    




<section class="aside-widget widget-categories content-padding-large soft-size--large soft-style--box">
  <h2 class="widget-header">
    <div class="title">
      <span>Categories</span>
    </div>
  </h2>
  <div class="widget-body">
    <ul class="categories-list">
      
        <li>
          <a href="https://Rclurn.github.io/categories/development/">Development</a>
          <span>11</span>
        </li>
      
        <li>
          <a href="https://Rclurn.github.io/categories/%E5%B7%A5%E5%85%B7%E7%AE%B1/">工具箱</a>
          <span>3</span>
        </li>
      
        <li>
          <a href="https://Rclurn.github.io/categories/%E4%B8%8A%E5%88%86%E6%9D%80%E5%99%A8/">上分杀器</a>
          <span>2</span>
        </li>
      
        <li>
          <a href="https://Rclurn.github.io/categories/%E7%AB%9E%E8%B5%9B/">竞赛</a>
          <span>1</span>
        </li>
      
        <li>
          <a href="https://Rclurn.github.io/categories/%E7%AE%97%E6%B3%95/">算法</a>
          <span>1</span>
        </li>
      
        <li>
          <a href="https://Rclurn.github.io/categories/%E9%9D%A2%E8%AF%95/">面试</a>
          <span>1</span>
        </li>
      
    </ul>
  </div>

  
</section>


    




  </aside>
</div>
  </main><footer class="footer-container layout-block">
  
  <div class="social-icons">
    
      <a class="soft-size--primary soft-style--box" href="https://github.com/rnaker" target="_blank" rel="noopener noreferrer">
          
        <svg class="icon icon-github" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
          <path d="M64.6 512c0 195.6 125.4 361.9 300.1 422.9 23.5 5.9 19.9-10.8 19.9-22.2v-77.6c-135.8 15.9-141.3-74-150.5-89-18.5-31.5-61.9-39.5-49-54.5 31-15.9 62.5 4 98.9 58 26.4 39.1 77.9 32.5 104.1 26 5.7-23.5 17.9-44.5 34.7-60.9-140.7-25.2-199.4-111.1-199.4-213.3 0-49.5 16.4-95.1 48.4-131.8-20.4-60.6 1.9-112.4 4.9-120.1 58.2-5.2 118.5 41.6 123.3 45.3 33.1-8.9 70.8-13.7 112.9-13.7 42.4 0 80.3 4.9 113.5 13.9 11.3-8.6 67.3-48.8 121.4-43.9 2.9 7.7 24.7 58.3 5.5 118.1 32.5 36.8 49 82.8 49 132.4 0 102.3-59 188.3-200.2 213.2 23.5 23.3 38.1 55.5 38.1 91.1v112.7c0.8 9 0 17.9 15.1 17.9C832.7 877 960.4 709.4 960.4 512.1c0-247.5-200.6-447.9-447.9-447.9C265 64.1 64.6 264.5 64.6 512z"></path>
        </svg>
        

        

        

        

        
      </a>
    
      <a class="soft-size--primary soft-style--box" href="https://weibo.com/u/5561168966" target="_blank" rel="noopener noreferrer">
        

        

        

          
        <svg class="icon icon-weibo" viewBox="0 0 1025 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
          <path d="M385.682429 733.696q11.995429-19.456 6.290286-39.424t-25.746286-28.598857q-19.456-7.972571-41.691429-0.585143t-34.304 26.258286q-12.580571 19.456-7.460571 39.131429t24.576 28.891429 42.569143 1.462857 35.693714-27.136zM439.442429 664.576q4.534857-7.460571 1.974857-15.140571t-10.020571-10.605714q-7.972571-2.852571-16.310857 0.292571t-12.288 10.605714q-9.728 17.700571 7.460571 25.746286 7.972571 2.852571 16.603429-0.292571t12.580571-10.605714zM538.843572 725.723429q-25.746286 58.294857-90.258286 85.723429t-128 6.875429q-61.147429-19.456-84.260571-72.265143t3.730286-107.154286q26.843429-53.174857 86.601143-79.433143t120.32-10.825143q63.414857 16.603429 90.550857 68.315429t1.462857 108.836571zM717.165858 634.294857q-5.12-54.857143-50.834286-97.133714t-119.149714-62.317714-156.891429-11.995429q-127.414857 13.165714-211.163429 80.822857t-75.702857 151.113143q5.12 54.857143 50.834286 97.133714t119.149714 62.317714 156.891429 11.995429q127.414857-13.165714 211.163429-80.822857t75.702857-151.113143zM893.147572 636.562286q0 38.838857-21.138286 79.725714t-62.317714 78.262857-96.256 67.145143-129.170286 47.396571-154.550857 17.700571-157.110857-19.163429-137.435429-53.174857-98.011429-86.308571-37.156571-114.029714q0-65.682286 39.716571-139.995429t112.859429-147.456q96.548571-96.548571 195.145143-134.875429t140.873143 4.022857q37.156571 36.571429 11.410286 119.442286-2.267429 7.972571-0.585143 11.410286t5.705143 4.022857 8.265143-0.292571 7.68-1.974857l3.437714-1.170286q79.433143-33.718857 140.580571-33.718857t87.405714 34.889143q25.746286 35.986286 0 101.741714-1.170286 7.460571-2.56 11.410286t2.56 7.168 6.875429 4.315429 9.728 3.437714q32.548571 10.313143 58.88 26.843429t45.714286 46.592 19.456 66.56zM850.871001 279.990857q23.990857 26.843429 31.158857 62.025143t-3.730286 67.145143q-4.534857 13.165714-16.822857 19.456t-25.453714 2.267429q-13.165714-4.534857-19.456-16.822857t-2.267429-25.453714q11.410286-35.986286-13.677714-63.414857t-61.147429-19.968q-13.677714 2.852571-25.746286-4.534857t-14.262857-21.138286q-2.852571-13.677714 4.534857-25.453714t21.138286-14.555429q34.304-7.460571 68.022857 3.145143t57.709714 37.449143zM954.295001 186.88q49.737143 54.857143 64.292571 127.122286t-7.68 138.020571q-5.12 15.433143-19.456 22.820571t-29.696 2.267429-22.820571-19.456-2.852571-29.696q16.018286-46.884571 5.705143-98.304t-45.714286-90.258286q-35.401143-39.424-84.553143-54.564571t-98.889143-4.827429q-16.018286 3.437714-29.696-5.412571t-17.115429-24.868571 5.412571-29.403429 24.868571-16.822857q70.290286-14.848 139.410286 6.582857t118.857143 76.873143z"></path>
        </svg>
        

        
      </a>
    
      <a class="soft-size--primary soft-style--box" href="https://www.zhihu.com/people/miku-84" target="_blank" rel="noopener noreferrer">
        

        

        

        

          
        <svg class="icon icon-zhihu" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg">
          <path d="M544.949 561.422s0-71.387-34.779-75.050c-34.779-3.663-142.775 0-142.775 0v-219.654h161.078s-1.83-73.219-32.949-73.219h-261.755l43.93-117.148s-65.897 3.663-89.692 45.761-98.844 252.604-98.844 252.604 25.627 10.983 67.726-20.134c42.101-31.116 56.743-86.033 56.743-86.033l76.879-3.663 1.83 223.316s-133.621-1.83-161.078 0c-27.457 1.83-42.101 75.050-42.101 75.050h203.182s-18.307 124.47-69.557 214.164c-53.085 89.692-151.929 161.078-151.929 161.078s71.387 29.287 140.947-10.983c69.557-42.101 120.811-223.316 120.811-223.316l162.912 203.182s14.643-97.013-1.83-124.47c-18.307-27.457-113.49-137.283-113.49-137.283l-42.101 36.607 29.287-120.811h177.552zM587.050 188.010l-1.83 660.793h65.897l23.795 82.37 115.321-82.37h162.912v-660.793h-366.091zM879.92 775.584h-76.879l-97.013 75.050-21.965-75.050h-20.134v-512.527h215.991v512.527z"></path>
        </svg>
        
      </a>
    
  </div>
  

  <div class="colour-bar"></div>
  
  
  <p>© 2021 <a href="https://github.com/miiiku/hugo-theme-kagome">kagome</a>.</p>
  

  

  <p>
    Powered by
    <a href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a>
    Theme - 
    <a href="https://github.com/miiiku/hugo-theme-kagome" target="_blank" rel="noopener noreferrer author">kagome</a>
  </p>

  <p>
    <a href="javascript:;" id="theme-light">🌞 light</a>
    <a href="javascript:;" id="theme-dark">🌛 dark</a>
    <a href="javascript:;" id="theme-auto">🤖️ auto</a>
  </p>
</footer>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>






</body>

</html>